\chapter{Cost-sensitive classification}\label{ch:3}

\begin{remark}{Outline}
In this chapter, we introduce the problem of cost-sensitive classification. Standard 
classification models aim at minimizing the misclassification of examples, in which an example is 
misclassified if the predicted class is different from the true class. However, this is not the 
case in many real-world applications.
In this chapter, first, we introduce cost-sensitive classification in Section~\ref{sec:3:intro}. 
Then, in Section~\ref{sec:3:class-dependent}, we present the problem of 
class-dependent cost-sensitive classification. Then, in Section~\ref{sec:3:example-dependent}, we 
present the general framework of example-dependent cost-sensitive classification. Within this 
section, we first introduce a method for defining the type of cost-sensitivity of a problem. 
Afterwards, we present the different cost-sensitive performance evaluation measures. Lastly, we 
present state-of-the-art example-dependent cost-sensitive methods, namely,  cost-proportionate 
rejection-sampling 
and cost-proportionate over-sampling.
\end{remark}


\section{Introduction}
\label{sec:3:intro}

  Classification methods are used to predict the class of different examples given their features.
  Standard methods aim at maximizing the accuracy of the predictions, in which an example is 
  correctly classified if the predicted class is the same the as true class. This traditional 
  approach assumes that all correctly classified and misclassified examples carry the same cost. 
  This, however, is not the case in   many real-world applications.   Methods that use different 
  misclassification costs are known as cost-sensitive  classifiers. Typical cost-sensitive 
  approaches assume a constant cost for each type of error, in  the sense that, the cost depends on 
  the class and is the same among examples \citep{Elkan2001,Kim2012}. Nevertheless, this 
  class-dependent approach is not realistic in many   real-world applications.
  
  For example in credit card fraud detection, failing to detect a fraudulent transaction may have 
  an economical impact from a few to thousands of Euros, depending on the particular transaction 
  and card holder \citep{Sahin2013}. In churn modeling, a model is used for predicting which
  customers are more likely to abandon a service provider. In this context, failing to identify a 
  profitable or unprofitable churner has a significant different financial impact 
  \citep{Glady2009}. Similarly, in direct marketing, wrongly predicting that a customer will not 
  accept an offer when in fact he will, has a different impact than the other way around 
  \citep{Zadrozny2003}. Also in credit scoring, where declining good customers has a non constant 
  impact since not all  customers generate the same profit \citep{Verbraken2014}. Lastly, in the 
  case of intrusion   detection, classifying a benign connection as malicious has a different cost 
  than when a   malicious connection is accepted \citep{Ma2011}.
  
  In order to deal with these specific types of cost-sensitive problems, called example-dependent
  cost-sensitive, some methods have been proposed recently. However, the literature on 
  example-dependent cost-sensitive methods is limited, mostly because there is a lack of publicly 
  available datasets that fit the problem \citep{MacAodha2013}. Standard solutions consist in 
  modifying the training set by re-weighting the examples proportionately to the misclassification 
  costs \citep{Elkan2001,Zadrozny2003}.

  
\section{Class-dependent cost-sensitive classification}
\label{sec:3:class-dependent}

The literature in cost-sensitive classification is mostly focused in class-dependent problems 
\citep{Elkan2001}, where 
the cost of misclassification is associated with the class. Usually, the cost of misclassifying a 
positive example is denoted by $C_{FN}$ and the one of misclassifying a negative example is denoted 
by $C_{FP}$. Conceptually, $C_{FN}\ge0$ and $C_{FP}\ge0$; moreover, they are normally defined such
that $C_{FN}+C_{FP}=2$ \citep{Flach2011a}, as when $C_{FN}=C_{FP}=1$ represents the case of 
cost-insensitive classification. Using the previous notation, a class-dependent cost measure is 
defined as \citep{Wang2014}:
\begin{equation}
  Cost_{cd}(f(\mathcal{S})) = C_{FP} \cdot FP + C_{FN} \cdot FN.
\end{equation}
%where $FP$ and $FN$ are the number of false positives and false negatives, respectively.

Over the past decades, various algorithms have been proposed for class-dependent cost-sensitive 
classification in literature. Several authors have used modifications of the decision trees that 
take into account the different class-dependent costs 
\citep{Draper1994,Ting2002,Ling2004,Li2005,Kretowski2006,Vadera2010,Lomax2013}.
Similarly, applications of bagging and boosting algorithms have been used for cost-sensitive 
classification \citep{Nesbitt2010,Street2008,Masnadi-shirazi2011,Fan1999}. Recently, various 
variations to support vector machines have also been used for this problem
\citep{Li2010,Masnadi-shirazi2010}. Lastly, online learning algorithms have also been used for 
cost-sensitive tasks \citep{Wang2014}.

Following the example shown in Section~\ref{sec:2:classification}, we now assume that 
misclassifying a negative example has a cost of $C_{FN}=0.2$ and for a positive example, the cost 
is  $C_{FP}=1.8$. Under this scenario, misclassifying a positive example has a much higher cost 
than misclassifying a negative one. Taking that into account, in \figurename{~\ref{fig:3:1}, we show 
an algorithm (Algorithm3), that focused on maximizing the correct classification of the positives.
In the following table, we compare the results of the standard measures and the class-dependent 
cost, of Algorithm3 and the classification algorithms presented in \figurename{~\ref{fig:2:2}} 
(Algorithm1) and \figurename{ \ref{fig:2:3}} (Algorithm2):
\begin{center}
    \footnotesize
  \begin{tabular}{l|c|c|c|c|c}
  Algorithm & Error & Recall & Precision & $F_1Score$ & $Cost_{cd}$ \\
  \hline
  Algorithm1 & 11.11\% & 87.8\%& 90\%& 88.8\% & 9.8\\ %FP = 4 , FN=5
  Algorithm2 & 5.3\% & 90.2\%& 94.9\%& 92.5\% & 7.6\\ %FP = 2 , FN=4
  Algorithm3 & 7.97\%& 92.68\% &86.36\%& 89.41\% & 6.6 \\
  \end{tabular}
\end{center}
\vspace{0.3cm}

\begin{figure}[t!]
  \centering
  \includegraphics{ch3_fig1}
  \caption{Class-dependent cost-sensitive classification algorithm. Since the cost of misclassifying 
positives and negatives is different, the algorithm focus on maximizing the correct classification 
of the positives.}
  \label{fig:3:1}
\end{figure}

It is found, that by focusing on the positives, Algorithm3 arises to a lower cost, even though the 
traditional metrics are worse for Algorithm3 than for Algorithm2. In conclusion, it is of highly 
importance to take into account the cost when evaluating and training a classification model.


\section{Example-dependent cost-sensitive classification}
\label{sec:3:example-dependent}

The class-dependent framework introduced in the previous section is highly restrictive, as 
assuming that the different costs are constant between classes is not realistic in many real world 
applications. In fraud detection, fraudulent transactions  can have a financial impact from 
hundreds or thousands of Euros \citep{Sahin2013}. 
In this context, the example-dependent costs can be represented using a 2x2 cost matrix 
\citep{Elkan2001}, that introduces the costs associated with   two types of correct   
classification, cost of true positives ($C_{TP_i}$), cost of true negatives ($C_{TN_i}$),   and the 
two  types of   misclassification errors, cost of false positives ($C_{FP_i}$), cost of false 
negatives   ($C_{FN_i}$), as   defined in \tablename{~\ref{tab:3:cost_matrix}}.

Conceptually, the cost of correct classification should always be lower than the cost of  
misclassification. These are referred to as the ``reasonableness`` conditions \citep{Elkan2001},   
and are defined as  $C_{FP_i} > C_{TN_i}$ and $C_{FN_i} > C_{TP_i}$.  Taking into account the 
``reasonableness`` conditions, a simpler cost matrix   with only one degree of freedom has been 
defined in \citep{Elkan2001}, by scaling and shifting the initial cost matrix. The simpler
cost-matrix is shown in \tablename{~\ref{tab:3:sim_cost_mat}.

\begin{table}[t]
    \centering
    \footnotesize
    \begin{tabular}{c|c|c}
      \multicolumn{1}{c|}{}  & Actual Positive& Actual Negative \\
      \multicolumn{1}{c|}{} & $y_i=1$& $y_i=0$ \\
      \hline
      Predicted Positive    & \multirow{ 2}{*}{$C_{TP_i}$} & \multirow{ 2}{*}{$C_{FP_i}$} \\
      $c_i=1$ & &\\
      \hline
      Predicted Negative    & \multirow{ 2}{*}{$C_{FN_i}$} & \multirow{ 2}{*}{$C_{TN_i}$} \\
      $c_i=0$ & &\\
    \end{tabular}
    \caption{Classification cost matrix}
    \label{tab:3:cost_matrix}
\end{table}  

 
\begin{table}[t]
  \centering
  \footnotesize    \begin{tabular}{c|c}
  \multirow{ 2}{*}{Negative} & \multirow{ 
  2}{*}{$C^*_{FN_i}=\frac{(C_{FN_i}-C_{TN_i})}{(C_{FP_i}-C_{TN_i})}$} \\
  \\
  \hline
  \multirow{ 2}{*}{Positive} & \multirow{ 
  2}{*}{$C^*_{TP_i}=\frac{(C_{TP_i}-C_{TN_i})}{(C_{FP_i}-C_{TN_i})}$} \\
  \\ 
  \end{tabular}
  \caption{Simplified classification cost matrix \citep{Elkan2001}}
  \label{tab:3:sim_cost_mat}
\end{table}  


\subsection{Example-dependent evaluation measures}
\label{sec:3:csmeasures}

  Common cost-insensitive evaluation measures, such as misclassification rate or \mbox{$F_1Score$}, 
  assume the same cost for the different misclassification errors. Using these measures is not 
  suitable for example-dependent cost-sensitive binary classification problems. Indeed, two 
  classifiers with equal misclassification rates but different numbers of false positives and 
  false negatives do not have the same impact on cost since \mbox{$C_{FP_i}\ne C_{FN_i}$};
  therefore, there is a need for a measure that takes into account the actual costs 
  $\{C_{TP_i},C_{FP_i},C_{FN_i},C_{TN_i}\}$ of each example $i$, as introduced in 
  Section~\ref{sec:3:example-dependent}.
  
  Let $\mathcal{S}$ be a set of $N$ examples $i$, $N=\vert \mathcal{S} \vert$, where each example 
  is represented by  the augmented feature vector $\mathbf{x}_i^*=[\mathbf{x}_i, 
  C_{TP_i},C_{FP_i},C_{FN_i},C_{TN_i}]$  and labeled using the class   label $y_i   \in \{0,1\}$. 
  A classifier $f$ which generates the   predicted label $c_i$ for each   element $i$ is trained  
  using the set $\mathcal{S}$. Then the cost of   using $f$ on $\mathcal{S}$ is calculated by
  \begin{equation}\label{eq:3:cost_total}
     Cost(f(\mathcal{S})) = \sum_{i=1}^N Cost(f(\mathbf{x}_i^*)),
  \end{equation}
  where
   \begin{align}\label{eq:3:cost}
    Cost(f(\mathbf{x}_i^*)) =& y_i(c_i C_{TP_i} + (1-c_i)C_{FN_i}) + \nonumber \\  
    & (1-y_i)(c_i C_{FP_i} + (1-c_i)C_{TN_i}).
  \end{align}

  However, the total cost may not be easy to interpret. In \citep{Whitrow2008}, a 
  \textit{normalized} cost measure was proposed, by dividing the total cost by the theoretical 
  maximum cost, which is the cost of misclassifying every example. The \textit{normalized} cost is 
  calculated using
  \begin{align}\label{eq:3:ncost}
    Cost_n(f(\mathcal{S})) = \frac{Cost(f(\mathcal{S}))}
    {\sum_{i=1}^N C_{FN_i} \cdot \mathbf{1}_0(y_i) 
    +  C_{FP_i} \cdot \mathbf{1}_1(y_i)  }.
  \end{align} 

  We propose similar approach in \citep{CorreaBahnsen2014b}, where the savings of using an 
  algorithm  are defined as the cost of the algorithm versus the cost of using no algorithm at all. 
  To do that, the cost of the costless class is defined as 
  \begin{equation}
    Cost_l(\mathcal{S}) = \min \{Cost(f_0(\mathcal{S})), Cost(f_1(\mathcal{S}))\},
  \end{equation}
  where 
  \begin{equation}\label{eq:3:f_a}
    f_a(\mathcal{S}) = \{a\}, \text{ with } a\in \{0,1\}.
  \end{equation}

  The cost improvement can be expressed as the cost savings as compared with $Cost_l(\mathcal{S})$. 
  \begin{equation}\label{eq:3:savings}
    Savings(f(\mathcal{S})) = \frac{ Cost_l(\mathcal{S}) - Cost(f(\mathcal{S}))}
    {Cost_l(\mathcal{S})}.
  \end{equation} 

\begin{figure}[t!]
  \centering
  \includegraphics{ch3_fig2}
  \caption{Example with example-dependent costs. Examples with the highest cost darker, and 
the   ones with the lowest cost lighter.}
  \label{fig:3:2}
\end{figure}

In order to illustrate this concept, we use the same example shown in 
Section~\ref{sec:2:classification}. However, now we add the variation in the costs by showing the 
examples with the highest cost darker, and the ones with the lowest cost lighter. The new example 
is shown in \figurename{~\ref{fig:3:2}}. Moreover, in the following table we summarize the 
different example-dependent costs:
  \begin{center}
    \footnotesize
  \begin{tabular}{l|c|c|c}
  Class & Cost light & Cost normal & Cost dark \\
  \hline
    Negative & 0.1 & 0.5 & 5.0 \\
    Positive & 1.0 & 2.0 & 10.0 \\
  \end{tabular}
  \end{center}
  
\begin{figure}[t!]
  \centering
  \includegraphics{ch3_fig3}
  \caption{Example-dependent cost-sensitive classification algorithm. The algorithm focus first on 
correctly classify the dark examples, as the cost of misclassification in this cases is 
several times more expensive than the other cases.}
  \label{fig:3:3}
\end{figure}

Taking into account the example-dependent costs, in \figurename{~\ref{fig:3:3}} (Algorithm4), we 
show a new algorithm that gives a higher importance on correctly classify the dark examples, as the 
cost of misclassification in this cases is several times more expensive than the other cases.
Furthermore, in the following table, we compare the results of the standard measures and the 
example-dependent savings of Algorithm4 and the classification algorithms presented in 
\figurename{~\ref{fig:2:2}} (Algorithm1), \figurename{ \ref{fig:2:3}} (Algorithm2) and 
\figurename{~\ref{fig:3:1}} (Algorithm3):
\begin{center}
    \footnotesize
  \begin{tabular}{l|c|c|c|c|c}
  Algorithm & Error & Recall & Precision & $F_1Score$ & $Savings$ \\
  \hline
  Algorithm1 & 11.11\% & 87.8\%& 90\%& 88.8\% & 46.86\%\\ %FP = 4 , FN=5
  Algorithm2 & 5.3\% & 90.2\%& 94.9\%& 92.5\% & 68.36\%\\ %FP = 2 , FN=4
  Algorithm3 & 7.97\%& 92.68\% &86.36\%& 89.41\% & 48.07\% \\
  Algorithm4 & 6.19\%& 92.68\% &90.48\%& 91.56\% & 87.42\% \\
  \end{tabular}
\end{center}
\vspace{0.3cm}

With these examples, we illustrate the impact that the costs have on the algorithms. 
Moreover, we highlight the importance of using the different costs when evaluating the different 
models. It is worth mentioning how distinct are the results if the costs are ignored and an 
algorithm is trained and evaluated not taking into account the different costs present in most 
real-world 
applications.

  
\subsection{Binary classification cost characteristic}
\label{sec:3:cost_characteristic}  

  A classification problem is said to be cost-insensitive if costs of both errors are equal. It 
  is class-dependent cost-sensitive if the costs are different but constant. Finally we talk 
  about an example-dependent cost-sensitive classification problem if the cost matrix is not 
  constant for all the examples.

  However, the definition above is not general enough. There are many cases when the cost matrix 
  is not constant and still the problem is cost-insensitive or class-dependent cost-sensitive. 
  For example, if the costs of correct classification are zero, $C_{TP_i}=C_{TN_i}=0$, 
  and the costs of misclassification are $C_{FP_i}=a_0\cdot z_i$ and $C_{FN_i}=a_1\cdot z_i$,
  where $a_0$ and $a_1$, are constants and $z_i$ is a random variable. This is an example of a cost 
  matrix that is not constant. However, $C^*_{FN_i}$ and $C^*_{TP_i}$ are constant, i.e. 
  $C^*_{FN_i}=(a_1\cdot z_i)/(a_0\cdot z_i)=a_1/a_0$ and $C^*_{TP_i}=0$ $\forall i$. In 
  this case the problem is cost-insensitive if $a_0=a_1$, or class-dependent cost-sensitive if 
  $a_0 \ne a_1$, even given the fact that the cost matrix is not constant.

  Nevertheless, using only the simpler cost matrix is not enough to define when a problem is 
  example-dependent cost-sensitive. To achieve this, we defined the following cost characteristic 
for a given binary classification problem as:
  \begin{equation}
    b_i = C^*_{FN_i}-C^*_{TP_i},
  \end{equation}
  and define its mean and standard deviation as $\mu_b$ and $\sigma_b$, respectively.

  Using $\mu_b$ and $\sigma_b$, we analyze different binary classification problems. 
%   
%   In the case 
%   of a cost-insensitive classification problem, for every example $i$ \mbox{$C_{FP_i}=C_{FN_i}$}
%   and $C_{TP_i}=C_{TN_i}$, leading to $b_i=1$ $\forall i$ or more generally $\mu_b=1$ and 
%   $\sigma_b=0$. For class-dependent cost-sensitive problems, the costs are not equal but 
%   constants \mbox{$C_{FP_i}\ne C_{FN_i}$} or \mbox{$C_{TP_i}\ne C_{TN_i}$}, leading to $b_i \ne 
%   1$ $\forall i$, or $\mu_b \ne 1$ and $\sigma_b=0$. Lastly, in the case of example-dependent 
%   cost-sensitive problems, the cost difference is non constant or $\sigma_b \ne 0$.
%   In summary 
  A binary classification problem is defined according to the following conditions:
  \begin{center}
    \footnotesize
    \begin{tabular}{c | c | l}
      $\mu_b$ & $\sigma_b$ & Type of classification problem \\
      \hline 
      && \\
      $1$ &  $0$ & cost-insensitive \\ &&\\
      $\ne 1$ & $0$ & class-dependent cost-sensitive \\ &&\\
      & $\ne 0$ & example-dependent cost-sensitive \\ 
    \end{tabular}
  \end{center}
  

\subsection{State-of-the-art methods}
\label{sec:3:costsampling}

  As mentioned earlier, taking into account the different costs associated with each example, 
  some methods have been proposed to make classifiers example-dependent cost-sensitive. These 
  methods may be grouped in two categories. Methods based on changing the class distribution of 
  the training data, which are known as cost-proportionate sampling methods; and direct cost 
  methods \citep{Wang2013}.

  A standard method to introduce example-dependent costs into classification algorithms is to 
  re-weight the training examples based on their costs, either by cost-proportionate 
  rejection-sampling \citep{Zadrozny2003}, or over-sampling \citep{Elkan2001}. The 
  rejection-sampling approach consists in selecting a random subset $\mathcal{S}_{r}$  by 
  randomly  selecting examples from $\mathcal{S}$, and accepting each example $i$ with 
  probability $w_i/ \max\limits_{1,\dots, N}\{w_i\}$, where $w_i$ is defined as the expected 
  misclassification error of example~$i$:
  \begin{equation}\label{eq_pred1}
    w_i = y_i\cdot C_{FN_i}+(1-y_i)\cdot C_{FP_i}.
  \end{equation}
  Lastly, the over-sampling method consists in creating a new set $\mathcal{S}_{o}$, by making 
  $w_i$ copies of each example $i$. However, cost-proportionate over-sampling increases the 
  training  since $\vert \mathcal{S}_{o}\vert >> \vert \mathcal{S} \vert$, and it also may result 
  in over-fitting  \citep{Drummond2003}. Furthermore, none of these methods uses the full cost 
  matrix but only the  misclassification costs.

  The second approach consists in using the predicted probability $\hat p_i$, estimated using a 
  given classifier $f$, and   modify the threshold $t$  such that the savings are maximized. 
  This method is called cost-sensitive thresholding \citep{Sheng2006}. The idea behind this 
  approach is to adaptively modify the probability threshold of an algorithm $f^t$ in order to 
  maximize the savings $Savings(f^t(\mathcal{S}))$ of the algorithm $f^t$ on a given set 
  $\mathcal{S}$. The threshold   is calculated  using the following equation
  \begin{equation}
   t_{thresholding} = \argmax_t Savings(f^t(\mathcal{S})).
  \end{equation}

  