\chapter{Cost-sensitive logistic regression}

\begin{remark}{Outline}
\todo{outline}
In this chapter, we present the well-known family of \textit{random forests}
methods. In Section~\ref{sec:4:bias-variance}, we first describe the bias-variance
decomposition of the prediction error and then present, in
Section~\ref{sec:4:ensemble}, how aggregating randomized models through
ensembles reduces the prediction error by decreasing the variance term in this
decomposition. In Section~\ref{sec:4:random-forests}, we revisit random forests
and its variants and study how randomness introduced into the decision trees
reduces prediction errors by decorrelating the decision
trees in the ensemble. Properties and features of random forests are then outlined
in Section~\ref{sec:4:features} while their consistency
is finally explored in Section~\ref{sec:4:consistency}.
\end{remark}

\section{Logistic regression}

Logistic regression is a classification model that, in the specific context of binary 
classification, estimates the posterior probability of the positive class, as the logistic sigmoid 
of a linear function of the feature vector \citep{Bishop2006}. The estimated probability  is 
evaluated as 
\begin{equation}
  \hat p_i = P(y=1 \vert \mathbf{x}_i) = h_{\theta}(\mathbf{x}_i) = 
  g\bigg(\sum_{j=1}^{k}{\theta^jx_i^j}\bigg),
\end{equation}
where $h_\theta(\mathbf{x}_i)$ refers to the hypothesis of $i$ given the parameters $\theta$,  
and  $g(\cdot)$ is the logistic sigmoid function, defined as
\begin{equation}
  g(z)=\frac{1}{(1+e^{-z})} 
\end{equation}
In the next Figure, the logistic sigmoid function is shown.
\begin{figure}[htbp]
  \centering
  \includegraphics{ch6_fig1}
  \caption{Sigmoid function}
  \label{fig:ch6:1}
\end{figure}

The problem then becomes on finding the right parameters that minimize a given cost function.   
Usually, in the case of logistic regression the cost function $J(\theta)$ refers to the negative   
logarithm of the likelihood, such that
\begin{equation}
  J(\theta)=\frac{1}{N}\sum_{i=1}^{N} J_i(\theta),
\end{equation}
where
\begin{align}
  J_i(\theta) =  -y_i\log(h_\theta(\mathbf{x}_i)) -(1-y_i)\log(1-h_\theta(\mathbf{x}_i)).
\end{align}
Therefore, the parameters are found using the following equation
\begin{align}
  \theta = \argmin_\theta J(\theta).
\end{align}
There are several methods used to estimate the logistic regression, in particular, maximum 
likelihood \citep{Hastie2009}, Newton, coordinate descent \citep{Murphy2012} and dual coordinate 
descent \citep{Yu2011}. Nevertheless, all these methods rely on the assuption of convexity of the
negative logarithm of the likelihood function. In the next section we analyze the convexity of the 
logistic regression.

\subsection{Convexity analysis of the logistic regression}

A function $f(\mathbf{x})$ which is twice-differentiable is convex if and only if its hessian 
matrix (matrix of second-order partial derivatives) is positive semi-definite \citep{Boyd2010}.
Therefore, with the objective of evaluating the convexity of the logistic function, first the first 
order partial derivatives are calculated as follows:

\begin{equation}
\left[ \begin{array}{c}
  \frac{\partial J(\theta)}{\partial \theta_1} \\[0.1in]	
  \frac{\partial J(\theta)}{\partial \theta_2} \\[0.1in]	
  \ldots \\[0.1in]	
  \frac{\partial J(\theta)}{\partial \theta_k}
\end{array} \right] =
\left[ \begin{array}{c}
  \frac{1}{N}\sum_{i=1}^{N}\left[x_i^{(1)}\left(h_\theta(\mathbf{x}_i)-y_i\right)\right]\\[0.1in]
  \frac{1}{N}\sum_{i=1}^{N}\left[x_i^{(2)}\left(h_\theta(\mathbf{x}_i)-y_i\right)\right]\\[0.1in]
  \ldots \\[0.1in]	
  \frac{1}{N}\sum_{i=1}^{N}\left[x_i^{(k)}\left(h_\theta(\mathbf{x}_i)-y_i\right)\right]\\[0.1in]	
\end{array} \right]
\end{equation}

Then, using the first order partial derivatives, the Hessian ($H$) can be generalized as
\begin{equation}
  \partialb{j1}{j2}=\frac{1}{N}\sum_{i=1}^{N}
  \left[\bigg(1-h_\theta(\mathbf{x}_i)\bigg)h_\theta(\mathbf{x}_i)x_i^{(j1)}x_i^{(j2)}\right],
\end{equation}
where, $j1$ and $j2$ $\in \{1\cdots k\}$. Which is the same as
\begin{equation}
H=\left[ \begin{array}{cccc}
  \partialb{1}{1} & \partialb{1}{2} & \cdots & \partialb{1}{k} \\[0.1in]  
  \partialb{2}{1} & \partialb{2}{2} & \cdots & \partialb{2}{k} \\[0.1in]  
  \cdots & \cdots & \cdots & \cdots \\[0.1in]  
  \partialb{k}{1} & \partialb{k}{2} & \cdots & \partialb{k}{k}  
\end{array} \right]
\end{equation}

For the cost function to be convex the Hessian matrix	must be positive-semidefinite, and
a function is positive-semidifinite if:  
\begin{equation}
  z^T\left[\nabla_x^2f(x)\right]z \ge 0 \quad  \forall z
\end{equation}
Applied to J($\theta$), it is nessesary to proof
\begin{equation}\label{eq:6:pos1}
  z^T\left[H \right]z \ge 0 \quad  \forall z
\end{equation}
Moreover, $H$ can be rewritten, using only the internal part of the summatory, since it do not 
dependent on $\theta$
\begin{equation}
 H = \frac{1}{N}\sum_{i=1}^{N} \left[ 
\bigg(1-h_\theta(\mathbf{x}_i)\bigg)h_\theta(\mathbf{x}_i)\mathbf{x}_i^T \mathbf{x} \right]. 
\end{equation}
Then, (\ref{eq:6:pos1}) becomes
\begin{align}
  z^T \left[\bigg(1-h_\theta(\mathbf{x}_i)\bigg)h_\theta(\mathbf{x}_i)\mathbf{x}_i^T 
\mathbf{x}\right] z,
\end{align}
which can be rewritten as
\begin{align}
  (1-h_\theta(\mathbf{x}_i))h_\theta(\mathbf{x}_i)\left(\mathbf{x}_i^Tz\right)^2 \ge 0.
\end{align}
Therefore, proving that $J(\theta)$ is convex, as $\left(\mathbf{x}_i^Tz\right)^2 
\ge 0$ and \\ $\left((1-h_\theta(\mathbf{x}_i))h_\theta(\mathbf{x}_i)\right)\ge 0$ because $0\ge 
h_\theta(\mathbf{x}_i) \ge 1$.

	
	\subsection{Analysis of the cost function}
	However, this cost function assigns the same 
  weight to different errors, both false positives and false negatives. As discussed before, this 
  is not the case in many real-world applications. In particular
			\quad When  $y^{(i)}==1$
			
			\quad $J(\theta)^{(i)}=-\log(h_\theta(\mathbf{x}_i)$
			
			\quad When $h_\theta(\mathbf{x}_i)\approx1$ then $J(\theta)^{(i)}\approx0$
			
			\quad Otherwise when $h_\theta(\mathbf{x}_i)\approx0$ then
			$J(\theta)^{(i)}\approx\infty$ \\

			When $y^{(i)}==0$
			
			\quad $J(\theta)^{(i)}=-\log(1-h_\theta(\mathbf{x}_i)$
			
			\quad\quad When $h_\theta(\mathbf{x}_i)\approx1$ then
			$J(\theta)^{(i)}\approx\infty$ 

			\quad\quad Otherwise when $h_\theta(\mathbf{x}_i)\approx0$ then
			$J(\theta)^{(i)}\approx0$ 
  which in the context of cost-sensitive classification means that $C_{TP_i}=C_{TN_i}\approx 0$ and 
  $C_{FP_i}=C_{FN_i}\approx \inf$.
	
	
\section{Cost-sensitive cost function}
  In order to incorporate the different costs from \tablename{ \ref{table_costmat}} into the 
  logistic regression, first we analyze the expected costs for each case
  \begin{equation*}
    J^c_i(\theta) = 
    \begin{cases}
      C_{TP_i}    & \text{if} \phantom{-}  y_i = 1 \text{ and } h_\theta(\mathbf{x}_i) \approx 1  \\
      C_{TN_i}    & \text{if} \phantom{-}  y_i = 0 \text{ and } h_\theta(\mathbf{x}_i) \approx 0  \\
      C_{FP_i}    & \text{if} \phantom{-}  y_i = 0 \text{ and } h_\theta(\mathbf{x}_i) \approx 1  \\
      C_{FN_i}    & \text{if} \phantom{-}  y_i = 1 \text{ and } h_\theta(\mathbf{x}_i) \approx 0 
    \end{cases}
  \end{equation*}
  Finally, we merge the different costs into a cost function which is dependent on new costs:
  \begin{align}\label{eq:CSLR}
    J^c(\theta)=\frac{1}{N} \sum_{i=1}^{N} \bigg( y_i(h_\theta(\mathbf{x}_i) C_{TP_i} + 
    (1-h_\theta(\mathbf{x}_i))C_{FN_i})  \nonumber\\ 
    +(1-y_i)(h_\theta(\mathbf{x}_i) C_{FP_i} + (1-h_\theta(\mathbf{x}_i))C_{TN_i}) \bigg).
  \end{align}
  
\todo{intro how to estimate the parameters}
\subsection{Genetic algorithms}

A Genetic Algorithm (GA) is an optimization technique that attempts to replicate natural evolution 
processes in which the individuals with the considered best characteristics to adapt to the 
environment are more likely to reproduce and survive. These advantageous individuals mate between 
them, producing descendants similarly characterized, so favorable characteristics are preserved and 
unfavorable ones destroyed, leading to the progressive evolution of the species.
GA aims to improve the solution to a problem by keeping the best combination of input variables. The 
flow diagram presented in Fig. 2 describes the process. It starts with the definition of the problem 
to optimize, generating an objective function to evaluate the possible candidate solutions 
(chromosomes), i.e., the objective function is the way of determining which individual produces the 
best outcome. 

The next step is to generate an initial random population of n individuals called chromosomes that 
are symbolized by binary strings, where each binary position of the chromosome is called a gene and 
denotes a specific characteristic (input variable). Therefore the combination of all the different 
characteristics encoded in the string represents an individual who is a candidate for the solution.
Each chromosome is evaluated in the objective function and the best individuals are selected to 
survive for mating (parents), while the worse ones are discarded to make room for new descendants.  
There are many ways of pairing the selected chromosomes \citep{Haupt2004}. In this paper, a weighted 
cost pairing 
is used, which consists of assigning a selection probability according to each chromosome cost. That 
is, a chromosome with the higher cost has a greater probability of mating because cost maximization 
is desired.

After selecting the parent chromosomes with the chosen pairing method, the next step is to create a 
second generation of individuals, based on the information of the parents. There are several ways of 
mating. In this paper, two parents create one child. 
In order to transfer the parents binary information to the child, there are also different kinds 
of approaches such as the one-point crossover. The one-point crossover technique consists in 
selecting one random point on the parents string. The child is created in the following way: First, 
the parent1 transfers its binary code from the first gene to the crossover point. Then the parent2 
transfers its binary code from the crossover point to the last gene of the chromosome. New parents 
are randomly selected for each new child and the process continues until the chromosome population 
grows back to the original size n. 
Once the breeding process is completed, random mutation is used to alter a certain percentage of the 
genes of the chromosomes. The purpose of mutation is to introduce diversity into the population, 
allowing the algorithm to avoid local minima by generating new gene combinations in the chromosomes. 
The most common mutation procedure is the one called single point mutation. It is implemented by 
generating a random variable that indicates the position of the gene that will be modified, from the 
population of chromosomes. Generally, mutation is not allowed in the best solution chromosomes 
because these elite individuals are destined to propagate unchanged. In genetic algorithm this 
is called elitism.

Finally, after mutation is done the new generation of chromosomes is evaluated with the objective 
function and used in the next iteration of the described algorithm.
The algorithm iterates until a maximum number of chromosome generations are created or a 
satisfactory solution is reached.

	\begin{figure}[t]
	  \centering
    \includegraphics[width=8cm]{ch6_fig2}  
	  \caption{Flow analysis of a churn campaign \citep{Haupt2004}}
	  \label{fig:ch6:2}
	\end{figure}

\section{Experiments}