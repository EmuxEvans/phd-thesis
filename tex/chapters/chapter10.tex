\chapter{Conclusions}\label{ch:10}

This thesis deals with the problem of example-dependent cost-sensitive classification.
Several real-world business applications of classification models are example-dependent 
cost-sensitive, in the sense that the objective of using an algorithm is related to maximizing the 
profit of the company. Moreover, the different costs due to misclassification vary among examples. 
Particularly, we focused on four different real-world applications: credit card fraud 
detection, credit scoring, churn modeling and direct marketing. In all cases, evaluating a 
classification algorithm using traditional statistics such as misclassification rate or $F_1Score$, 
do not accurately represent the business oriented goals. Moreover, we founded, significant 
differences in the results, when using tradition cost-insensitive methods against example-dependent 
cost-sensitive methods.

First in \chaptername{ \ref{ch:background}}, we laid out the background for general classification 
methods, and their respective evaluation measures. Moreover, we introduce the problem of 
cost-sensitive learning, in particular, we define the differences between class-dependent and 
example-dependent problems. In addition, we present a evaluation measure that takes into account 
the real financial gains and losses of practical applications.

Then in \partname{~\textsc{\ref{part:1}}}, we analyzed and discussed four real-world 
classification problems, that are the focus of this thesis, in particular, credit card fraud 
detection, credit scoring, churn modeling and direct marketing. In general, we showed why each of 
the applications is example-dependent cost-sensitive, and we elaborated a framework for the 
analysis of each problem. The Part is organized in two Chapters. First, in 
\chaptername{~\ref{ch:3}}, we discussed the applications within financial risk management. Lastly, 
in \chaptername{~\ref{ch:4}}, the marketing analytics applications.

Finally in \partname{~\textsc{\ref{part:2}}}, we introduced our proposed example-dependent 
cost-sensitive methods. First, in \chaptername{~\ref{ch:5}}, we presented our Bayes minimum risk 
method. This method worked by including comparing the expected financial losses of different 
outcomes when classifying the examples in the different classes. Then, we focused on introducing the 
costs to the algorithms during the training phase. In particular in \chaptername{~\ref{ch:6}}, we 
introduced our method cost-sensitive logistic regression, and in \chaptername{~\ref{ch:7}}, we 
showed and discussed our previously proposed cost-sensitive decision trees algorithm. 
The cost-sensitive decision tree algorithm proved to be highly effective while maintaining the 
simplicity and interpretability of decision trees. However, this method suffer from high variance, 
to overcome that limitation, in \chaptername{~\ref{ch:8}}, we proposed framework for 
ensembles of cost-sensitive decision trees. Lastly, in \chaptername{~\ref{ch:9}}, we presented the 
library \mbox{\textit{CostCla}} that we developed as part of the thesis. This library is an 
open-source implementation of all the algorithms covered in this manuscript.
  
Overall, this thesis showed the importance of using the real example-dependent financial 
costs associated with real-world applications, since there are significant differences in the 
results when evaluating a model using a traditional cost-insensitive measure such as the accuracy 
or F1Score,  than when using the savings, leading to the conclusion of the importance of using the 
real practical financial costs of each context.

  
