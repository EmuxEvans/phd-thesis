% Abstract ====================================================================
\pdfbookmark[1]{Abstract}{Abstract}
\chapter*{Abstract}

Several real-world classification problems are example-dependent cost-sensitive in nature, where the 
costs due to misclassification vary between examples and not only within classes. However, standard 
classification methods do not take these costs into account, and assume a constant cost of 
misclassification errors. This approach is not realistic in many real-world applications. For  
example in credit card fraud detection, failing to detect a fraudulent transaction may have an 
economical impact from a few to thousands of Euros, depending on the particular transaction and card 
holder. In churn modeling, a model is used for predicting which customers are more likely to 
abandon a service provider. In this context, failing to identify a   profitable or unprofitable 
churner has a significant different economic   result. Similarly, in direct marketing, wrongly 
predicting that a customer   will not accept an offer when in fact he will, may have different 
financial impact, as not all   customers generate the same profit. Lastly, in credit scoring, 
accepting   loans from bad customers does not have the same economical loss, since customers have 
different   credit lines, therefore, different profit.

Accordingly, the goal of this thesis is to provide an in-depth analysis of example-dependent 
cost-sensitive classification. In the first part, we give the  general concepts of classification 
and cost-sensitive classification, and we present the cost-sensitive problem. The second part of 
this manuscript is dedicated to explain the particularities of the four real-world classification 
problems that are the focus of this thesis, in particular, credit card fraud detection, credit 
scoring, churn modeling and direct marketing. In general, we show why each of these applications is 
example-dependent cost-sensitive, and we elaborate a framework for the analysis of each problem. 

Afterwards, in the third part of this work, we propose four example-dependent cost-sensitive 
methods. First, we present the Bayes minimum risk algorithm which consist in quantifying tradeoffs 
between various decisions using probabilities and the costs that accompany such decisions. Then, we 
introduce the cost-sensitive logistic regression technique, this algorithm is based in a new 
logistic regression cost function, one that takes into account the real costs due to 
misclassification and correct classification. Subsequently, we show the cost-sensitive decision 
trees algorithm which is based on incorporating the different example-dependent costs into a new 
cost-based impurity measure and a new cost-based pruning criteria. Lastly, we introduce the 
framework of ensembles of example-dependent cost-sensitive decision-trees, by training 
example-dependent cost-sensitive decision trees using four different random inducer methods and then 
blending them using three different combination approaches. Moreover, we present the library 
\mbox{\textit{CostCla}} developed as part of the thesis. This library is an open-source 
implementation of all the algorithms covered in this manuscript.

Finally, the experimental results show the importance of using the real example-dependent financial 
costs associated with real-world applications. We found that there are significant differences 
in the results when evaluating a model using a traditional cost-insensitive measure such as the 
accuracy or F1Score, than when using the financial savings. Moreover, the results show that the 
proposed algorithms have better results for all databases, in the sense of higher savings.